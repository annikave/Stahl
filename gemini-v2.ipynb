{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97d92d92-7cc0-4b32-8691-5d66148eeaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Praegune töökaust: C:\\Users\\Kasutaja\\Desktop\\keeletehnoloogia_2024\\eksam2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Praegune töökaust:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37d7bf55-2aee-4e04-925a-e6a49159613b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uus töökaust: C:\\Users\\Kasutaja\\Desktop\\helle\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\Kasutaja\\\\Desktop\\\\helle\")\n",
    "print(\"Uus töökaust:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9689d413-ed8c-41e1-bc83-8eeae5dfdaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import base64\n",
    "import logging\n",
    "import google.generativeai as genai\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple\n",
    "import io\n",
    "\n",
    "# Set your API key as an environment variable (or directly in code for testing ONLY)\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"my-api-key-here\"  # Replace with your actual key\n",
    "\n",
    "# Configure the API client\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "class DictionaryCorrector:\n",
    "    def __init__(self):\n",
    "        self.setup_logging()\n",
    "        self.system_prompt = \"\"\"You are an expert in historical linguistics and lexicography, specifically focused on correcting entries from a 1732 Estonian-German dictionary. Compare the CSV entries with the original dictionary image and identify any discrepancies or errors. Focus on:\n",
    "\n",
    "1. Spelling accuracy (including special characters and diacritics) - do not insert the letter \"õ\" where it is not originally present.\n",
    "2. Completeness of entries\n",
    "3. Correct segmentation of information across fields\n",
    "4. Proper handling of examples and their translations\n",
    "5. Accurate recording of grammatical information\n",
    "6. Do not alter letter shapes - retain the original letter forms as recorded in the dictionary.\n",
    "\n",
    "For each correction:\n",
    "1. Document the original entry\n",
    "2. Explain the error found\n",
    "3. Provide the corrected version\n",
    "4. Note the confidence level of the correction (High/Medium/Low)\"\"\"\n",
    "\n",
    "    def setup_logging(self):\n",
    "        log_format = '%(asctime)s - %(levelname)s\\nLocation: %(pathname)s:%(lineno)d\\nMessage: %(message)s\\n'\n",
    "        logging.basicConfig(level=logging.INFO, format=log_format, handlers=[logging.FileHandler('correction-log.log'), logging.StreamHandler()])\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def get_entries_for_page(self, entries: List[Dict], png_filename: str) -> List[Dict]:\n",
    "        try:\n",
    "            page_str = png_filename.split('_')[-1].replace('.png', '')\n",
    "            if not page_str.isdigit():\n",
    "                raise ValueError(f\"Invalid page number format in filename: {png_filename}\")\n",
    "            page_num = int(page_str)\n",
    "\n",
    "            avg_entries_per_page = 50\n",
    "            overlap = 15\n",
    "\n",
    "            start_idx = max(0, (page_num - 1) * avg_entries_per_page)\n",
    "            end_idx = min(len(entries), page_num * avg_entries_per_page + overlap)\n",
    "\n",
    "            page_entries = entries[start_idx:end_idx]\n",
    "\n",
    "            if page_entries:\n",
    "                self.logger.info(f\"Page {page_num}: Processing entries {start_idx} to {end_idx}\\nFirst entry: {page_entries[0]['estonian_headword']}\\nLast entry: {page_entries[-1]['estonian_headword']}\")\n",
    "            else:\n",
    "                self.logger.warning(f\"No entries found for page {page_num}\")\n",
    "\n",
    "            return page_entries\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error determining page entries: {str(e)}\")\n",
    "            return entries\n",
    "\n",
    "    def read_csv(self, filepath: str) -> List[Dict]:\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                reader = csv.DictReader(f)\n",
    "                return list(reader)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error reading CSV file: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def encode_image(self, image_path: str) -> str:\n",
    "        try:\n",
    "            with open(image_path, 'rb') as image_file:\n",
    "                return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error encoding image: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def compare_entries(self, csv_entries: List[Dict], image_path: str) -> Tuple[List[Dict], List[Dict], List[Dict]]:\n",
    "        \"\"\"Compare CSV entries with dictionary page and identify corrections.\"\"\"\n",
    "        try:\n",
    "            base64_image = self.encode_image(image_path)\n",
    "\n",
    "            # Construct the comparison prompt\n",
    "            comparison_prompt = f\"\"\"{self.system_prompt}\\n\\n\n",
    "            Please compare these CSV entries with the dictionary page image and identify any discrepancies. \n",
    "            If entries are missing, add them to the list in the format provided.\\n\\nCSV Entries:\\n\n",
    "            {json.dumps(csv_entries, indent=2, ensure_ascii=False)}\"\"\"\n",
    "\n",
    "            # Create a GenerativeModel instance\n",
    "            model = genai.GenerativeModel(\"models/gemini-2.0-flash-exp\")\n",
    "\n",
    "            # Start a ChatSession\n",
    "            chat = model.start_chat()\n",
    "\n",
    "            # Send the message and get the response\n",
    "            response = chat.send_message(content={\"text\": comparison_prompt})\n",
    "\n",
    "            # Process the response\n",
    "            if response and response.text:\n",
    "                return self.parse_gemini_response(response.text)\n",
    "            else:\n",
    "                self.logger.error(\"API request failed: No response or no text in response.\")\n",
    "                raise Exception(\"API request failed: No response or no text in response.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in compare_entries: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def parse_gemini_response(self, response: str) -> Tuple[List[Dict], List[Dict], List[Dict]]:\n",
    "        try:\n",
    "            result = json.load(io.StringIO(response))\n",
    "        except json.JSONDecodeError as e:\n",
    "            self.logger.warning(f\"Failed to parse full JSON: {e}\")\n",
    "            json_start = response.find('{')\n",
    "            json_end = response.rfind('}') + 1\n",
    "            if json_start != -1 and json_end > json_start:\n",
    "                try:\n",
    "                    result = json.load(io.StringIO(response[json_start:json_end]))\n",
    "                    self.logger.info(f\"Extracted JSON: {result}\")\n",
    "                except json.JSONDecodeError as e:\n",
    "                    self.logger.error(f\"Failed to extract and parse JSON: {e}\")\n",
    "                    return [], [], []\n",
    "            else:\n",
    "                self.logger.error(\"No JSON found in response\")\n",
    "                return [], [], []\n",
    "    \n",
    "        corrections = result.get('corrections', [])\n",
    "        new_entries = result.get('new_entries', [])\n",
    "        uncertain = result.get('uncertain', [])\n",
    "        return corrections, new_entries, uncertain\n",
    "\n",
    "    except Exception as e:\n",
    "        self.logger.error(f\"Error parsing Gemini response: {str(e)}\")\n",
    "        return [], [], []\n",
    "\n",
    "    def apply_corrections(self, original_entries: List[Dict], corrections: List[Dict]) -> List[Dict]:\n",
    "        corrected_entries = original_entries.copy()\n",
    "        changes = []\n",
    "\n",
    "        for correction in corrections:\n",
    "            entry_index = next((i for i, entry in enumerate(corrected_entries) if entry['estonian_headword'] == correction['original_headword']), None)\n",
    "\n",
    "            if entry_index is not None:\n",
    "                old_entry = corrected_entries[entry_index].copy()\n",
    "                corrected_entries[entry_index].update(correction['corrected_entry'])\n",
    "                changes.append({'original': old_entry, 'corrected': corrected_entries[entry_index], 'confidence': correction.get('confidence', 'Unknown')})\n",
    "\n",
    "        self.log_changes(changes)\n",
    "        return corrected_entries\n",
    "\n",
    "    def apply_new_entries(self, original_entries: List[Dict], new_entries: List[Dict]) -> List[Dict]:\n",
    "        for new_entry in new_entries:\n",
    "            original_entries.append(new_entry['new_entry'])\n",
    "        return original_entries\n",
    "\n",
    "    def log_changes(self, changes: List[Dict]):\n",
    "        for change in changes:\n",
    "            self.logger.info(f\"\\nCorrection applied:\\nOriginal entry: {json.dumps(change['original'], ensure_ascii=False)}\\nCorrected entry: {json.dumps(change['corrected'], ensure_ascii=False)}\\nConfidence: {change['confidence']}\\n\")\n",
    "\n",
    "    def process_dictionary(self, csv_path: str, png_folder: str, output_csv: str):\n",
    "        try:\n",
    "            entries = self.read_csv(csv_path)\n",
    "            png_files = sorted([f for f in os.listdir(png_folder) if f.lower().endswith('.png')])\n",
    "\n",
    "            for png_file in png_files:\n",
    "                image_path = os.path.join(png_folder, png_file)\n",
    "                page_entries = self.get_entries_for_page(entries, png_file)\n",
    "                corrections, new_entries, uncertain = self.compare_entries(page_entries, image_path)\n",
    "\n",
    "                entries = self.apply_corrections(entries, corrections)\n",
    "                entries = self.apply_new_entries(entries, new_entries)\n",
    "\n",
    "                for entry in uncertain:\n",
    "                    self.logger.warning(f\"Uncertain entry needs review: {entry}\")\n",
    "\n",
    "            self.write_csv(entries, output_csv)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing dictionary: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def write_csv(self, entries: List[Dict], output_path: str):\n",
    "        try:\n",
    "            with open(output_path, 'w', newline='', encoding='utf-8') as f:\n",
    "                if entries:\n",
    "                    writer = csv.DictWriter(f, fieldnames=entries[0].keys())\n",
    "                    writer.writeheader()\n",
    "                    writer.writerows(entries)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error writing CSV file: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "def main():\n",
    "    csv_path = \"CSV-input.csv\"\n",
    "    png_folder = \"Helle-12-PNG\"  # Make sure this folder exists and contains PNGs\n",
    "    output_csv = \"output-Gem1-mj.csv\"\n",
    "\n",
    "    corrector = DictionaryCorrector()\n",
    "    corrector.process_dictionary(csv_path, png_folder, output_csv)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf880e5-f86f-4f0d-a4f0-2997dc9894f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
